{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a4a6f2",
      "metadata": {
        "id": "b4a4a6f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487bb36e-83e6-45bc-9ae4-9b860fabdc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping imblearn as it is not installed.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.1.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gower in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gower) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from gower) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kmodes in /usr/local/lib/python3.8/dist-packages (0.12.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.1.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.0->kmodes) (3.1.0)\n",
            "0.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall imblearn\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install gower\n",
        "!pip install kmodes\n",
        "# Initial imports.\n",
        "import re\n",
        "import gower\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlalchemy as sql\n",
        "import tensorflow as tf\n",
        "\n",
        "from kmodes.kmodes import KModes\n",
        "from sklearn.cluster import AgglomerativeClustering, DBSCAN, OPTICS\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.ensemble import RUSBoostClassifier, EasyEnsembleClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
        "from matplotlib import pyplot\n",
        "from getpass import getpass\n",
        "\n",
        "!python -c \"import imblearn;print(imblearn.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e14855",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87e14855",
        "outputId": "7deb16ba-8c50-429c-9f53-492bec7f016c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter database password··········\n"
          ]
        }
      ],
      "source": [
        "# Ask for the database pasword\n",
        "password = getpass('Enter database password')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04b8263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f04b8263",
        "outputId": "9d0b9985-8a60-462c-a756-99ce2538eb17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TVIV', 'TSDem', 'TB_SEC_III', 'TB_SEC_IV', 'TB_SEC_X', 'obstetric_violence']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Create engine to connect to database\n",
        "engine = sql.create_engine(f'postgresql://postgres:{password}@obstetric-violence.clstnlifxcx7.us-west-2.rds.amazonaws.com:5432/ENDIREH_2021')\n",
        "\n",
        "# Get list of table names\n",
        "sql.inspect(engine).get_table_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad74d14f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ad74d14f",
        "outputId": "db17097c-d7df-4d38-87cb-3628b004f178"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ID_PER     ID_VIV     UPM  VIV_SEL  HOGAR  N_REN  CVE_ENT  \\\n",
              "0  0100128.05.1.02  100128.05  100128        5      1      2        1   \n",
              "1  0101482.03.1.03  101482.03  101482        3      1      3        1   \n",
              "2  0101631.04.1.01  101631.04  101631        4      1      1        1   \n",
              "3  0101876.04.1.02  101876.04  101876        4      1      2        1   \n",
              "4  0102096.02.1.02  102096.02  102096        2      1      2        1   \n",
              "\n",
              "          NOM_ENT  CVE_MUN         NOM_MUN  ...  P10_8_6  P10_8_7 P10_8_8  \\\n",
              "0  AGUASCALIENTES        1  AGUASCALIENTES  ...      NaN      NaN     NaN   \n",
              "1  AGUASCALIENTES        1  AGUASCALIENTES  ...      NaN      NaN     NaN   \n",
              "2  AGUASCALIENTES        1  AGUASCALIENTES  ...      NaN      NaN     NaN   \n",
              "3  AGUASCALIENTES        1  AGUASCALIENTES  ...      2.0      2.0     2.0   \n",
              "4  AGUASCALIENTES        5     JESÚS MARÍA  ...      NaN      NaN     NaN   \n",
              "\n",
              "   P10_8_9  P10_8_10  P10_8_11 P10_8_12  P10_8_13  P10_8_14  P10_8_15  \n",
              "0      NaN       NaN       NaN      NaN       NaN       NaN       NaN  \n",
              "1      NaN       NaN       NaN      NaN       NaN       NaN       NaN  \n",
              "2      NaN       NaN       NaN      NaN       NaN       NaN       NaN  \n",
              "3      2.0       2.0       2.0      1.0       1.0       1.0       NaN  \n",
              "4      NaN       NaN       NaN      NaN       NaN       NaN       NaN  \n",
              "\n",
              "[5 rows x 170 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5bedba6-090b-45d8-a23b-5540326682d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_PER</th>\n",
              "      <th>ID_VIV</th>\n",
              "      <th>UPM</th>\n",
              "      <th>VIV_SEL</th>\n",
              "      <th>HOGAR</th>\n",
              "      <th>N_REN</th>\n",
              "      <th>CVE_ENT</th>\n",
              "      <th>NOM_ENT</th>\n",
              "      <th>CVE_MUN</th>\n",
              "      <th>NOM_MUN</th>\n",
              "      <th>...</th>\n",
              "      <th>P10_8_6</th>\n",
              "      <th>P10_8_7</th>\n",
              "      <th>P10_8_8</th>\n",
              "      <th>P10_8_9</th>\n",
              "      <th>P10_8_10</th>\n",
              "      <th>P10_8_11</th>\n",
              "      <th>P10_8_12</th>\n",
              "      <th>P10_8_13</th>\n",
              "      <th>P10_8_14</th>\n",
              "      <th>P10_8_15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0100128.05.1.02</td>\n",
              "      <td>100128.05</td>\n",
              "      <td>100128</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0101482.03.1.03</td>\n",
              "      <td>101482.03</td>\n",
              "      <td>101482</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0101631.04.1.01</td>\n",
              "      <td>101631.04</td>\n",
              "      <td>101631</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0101876.04.1.02</td>\n",
              "      <td>101876.04</td>\n",
              "      <td>101876</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0102096.02.1.02</td>\n",
              "      <td>102096.02</td>\n",
              "      <td>102096</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>5</td>\n",
              "      <td>JESÚS MARÍA</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 170 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5bedba6-090b-45d8-a23b-5540326682d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5bedba6-090b-45d8-a23b-5540326682d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5bedba6-090b-45d8-a23b-5540326682d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Read the obstetric_violence table and show the results\n",
        "RDS_df = pd.read_sql_table('obstetric_violence', con=engine)\n",
        "RDS_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d82ff068",
      "metadata": {
        "id": "d82ff068"
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the database to choose the features we will use to analyse\n",
        "df_copy = RDS_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0249a12",
      "metadata": {
        "id": "f0249a12"
      },
      "outputs": [],
      "source": [
        "# Remove columns that had data that wasn't usefull like ids, sampling information and table structure\n",
        "df_copy = df_copy.drop(columns=['ID_VIV', 'ID_PER' ,'UPM', 'VIV_SEL', 'HOGAR', 'N_REN', 'CVE_ENT', 'CVE_MUN', 'COD_RES', 'EST_DIS', 'UPM_DIS', 'ESTRATO', 'NOMBRE', 'SEXO', 'COD_M15', 'CODIGO', 'REN_MUJ_EL', 'REN_INF_AD', 'N_REN_ESP','T_INSTRUM', 'FAC_VIV', 'FAC_MUJ', 'PAREN', 'GRA', 'NOM_MUN', 'P4_4_CVE'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a820335c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "a820335c",
        "outputId": "a4d36d31-718a-470c-9ef1-e39ded57d2d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           NOM_ENT DOMINIO  EDAD   NIV  P1_1  P1_2  P1_2_A  P1_3  P1_4_1  \\\n",
              "0   AGUASCALIENTES       U    45  11.0     3     3       5    15       1   \n",
              "1   AGUASCALIENTES       R    31   4.0     3     2       3     5       1   \n",
              "2  BAJA CALIFORNIA       U    27   4.0     3     1       1     3       2   \n",
              "3  BAJA CALIFORNIA       U    25  10.0     3     1       3     6       2   \n",
              "4           COLIMA       U    30   9.0     3     2       4    10       2   \n",
              "\n",
              "   P1_4_2  ...  P10_8_6  P10_8_7  P10_8_8  P10_8_9  P10_8_10  P10_8_11  \\\n",
              "0       1  ...      2.0      2.0      2.0      2.0       2.0       2.0   \n",
              "1       1  ...      2.0      2.0      2.0      2.0       2.0       2.0   \n",
              "2       1  ...      2.0      2.0      2.0      2.0       2.0       2.0   \n",
              "3       1  ...      2.0      1.0      2.0      2.0       2.0       2.0   \n",
              "4       1  ...      NaN      NaN      NaN      NaN       NaN       NaN   \n",
              "\n",
              "   P10_8_12  P10_8_13  P10_8_14  P10_8_15  \n",
              "0       1.0       1.0       1.0       NaN  \n",
              "1       1.0       1.0       1.0       NaN  \n",
              "2       2.0       NaN       NaN       NaN  \n",
              "3       1.0       1.0       1.0       NaN  \n",
              "4       NaN       NaN       NaN       NaN  \n",
              "\n",
              "[5 rows x 144 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13847531-554e-41c0-849f-ed5c7a114abf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NOM_ENT</th>\n",
              "      <th>DOMINIO</th>\n",
              "      <th>EDAD</th>\n",
              "      <th>NIV</th>\n",
              "      <th>P1_1</th>\n",
              "      <th>P1_2</th>\n",
              "      <th>P1_2_A</th>\n",
              "      <th>P1_3</th>\n",
              "      <th>P1_4_1</th>\n",
              "      <th>P1_4_2</th>\n",
              "      <th>...</th>\n",
              "      <th>P10_8_6</th>\n",
              "      <th>P10_8_7</th>\n",
              "      <th>P10_8_8</th>\n",
              "      <th>P10_8_9</th>\n",
              "      <th>P10_8_10</th>\n",
              "      <th>P10_8_11</th>\n",
              "      <th>P10_8_12</th>\n",
              "      <th>P10_8_13</th>\n",
              "      <th>P10_8_14</th>\n",
              "      <th>P10_8_15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>U</td>\n",
              "      <td>45</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AGUASCALIENTES</td>\n",
              "      <td>R</td>\n",
              "      <td>31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BAJA CALIFORNIA</td>\n",
              "      <td>U</td>\n",
              "      <td>27</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BAJA CALIFORNIA</td>\n",
              "      <td>U</td>\n",
              "      <td>25</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COLIMA</td>\n",
              "      <td>U</td>\n",
              "      <td>30</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 144 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13847531-554e-41c0-849f-ed5c7a114abf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13847531-554e-41c0-849f-ed5c7a114abf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13847531-554e-41c0-849f-ed5c7a114abf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Removing women that did not had a pregnancy on the last 5 years\n",
        "df_copy = df_copy[df_copy.P10_2 == 1.0].reset_index(drop=True)\n",
        "df_copy.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39521320",
      "metadata": {
        "id": "39521320"
      },
      "outputs": [],
      "source": [
        "#List of each target question we chose \n",
        "target = ['P10_8_1',\n",
        "'P10_8_2',\n",
        "'P10_8_3',\n",
        "'P10_8_4',\n",
        "'P10_8_5',\n",
        "'P10_8_6',\n",
        "'P10_8_7',\n",
        "'P10_8_8',\n",
        "'P10_8_9',\n",
        "'P10_8_10',\n",
        "'P10_8_11',\n",
        "'P10_8_12',\n",
        "'P10_8_13',\n",
        "'P10_8_14',\n",
        "'P10_8_15']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2cbbbe",
      "metadata": {
        "id": "ac2cbbbe"
      },
      "outputs": [],
      "source": [
        "# Function to create a dataset for each target question and store it in a dictionary\n",
        "def DataFrame_X_y_split(source_df,targets, df_X_y_dict = {}):\n",
        "    # Create a copy of the dataframe to avoid making changes in the original\n",
        "    df = source_df.copy()\n",
        "\n",
        "    # Format the Income related columns since 999999 is used to declare a non-specified income and thus can be used as 0\n",
        "    income_columns = ['P4_2', 'P4_5_AB', 'P4_7_AB', 'P4_9_1', 'P4_9_2', 'P4_9_3', 'P4_9_4', 'P4_9_5', 'P4_9_6', 'P4_9_7']\n",
        "    df[income_columns] = df[income_columns].fillna(0)\n",
        "    df[income_columns].apply(lambda x: x.astype(int))    \n",
        "    df[(df[income_columns] >= 999998)][income_columns] = 0\n",
        "\n",
        "    # Declare which features use text as their value (categorical features)\n",
        "    string_columns = ['NOM_ENT', 'DOMINIO','P1_1','P1_4_1','P1_4_2','P1_4_3','P1_4_4','P1_4_5','P1_4_6','P1_4_7','P1_4_8',\n",
        "                      'P1_4_9', 'P1_5', 'P1_6', 'P1_6', 'P1_8','P1_10_1','P1_10_2','P1_10_3','P1_10_4', 'P2_5','P2_6', \n",
        "                      'P2_8','P2_9','P2_10','P2_11','P2_12','P2_13','P2_14','P2_15', 'P2_16','P3_1','P3_2','P3_3','P3_4',\n",
        "                      'P3_5','P3_6','P3_7', 'P3_8', 'P4AB_1', 'P4B_1','P4B_2','P4C_1','P4BC_3','P4BC_4','P4BC_5','P4_1',\n",
        "                      'P4_2_1','P4_3', 'P4_4','P4_5_1_AB','P4_6_AB','P4_8_1','P4_8_2','P4_8_3','P4_8_4','P4_8_5','P4_8_6',\n",
        "                      'P4_8_7', 'P4_10_2_1', 'P4_10_2_2', 'P4_10_2_3', 'P4_10_3_1', 'P4_10_3_2', 'P4_10_3_3','P4_11',\n",
        "                      'P4_12_1','P4_12_2','P4_12_3','P4_12_4','P4_12_5','P4_12_6','P4_12_7', 'P4_13_1', 'P4_13_2', 'P4_13_3',\n",
        "                      'P4_13_4', 'P4_13_5', 'P4_13_6', 'P4_13_7', 'P10_1_1','P10_1_2','P10_1_3','P10_1_4','P10_1_5','P10_1_6',\n",
        "                      'P10_1_7','P10_1_8','P10_1_9','P10_5_01','P10_5_02','P10_5_03','P10_5_04','P10_5_05','P10_5_06','P10_5_07',\n",
        "                      'P10_5_08','P10_5_09','P10_5_10','P10_5_11','P10_7']\n",
        "    \n",
        "    # Change dtype of string columns to object\n",
        "    df.loc[:,df.columns.isin(string_columns)] = df.loc[:,df.columns.isin(string_columns)].fillna('b')\n",
        "    df.loc[:,df.columns.isin(string_columns)] = df.loc[:,df.columns.isin(string_columns)].astype(object)\n",
        "\n",
        "    # Change the remaining columns to integer datatype\n",
        "    df.loc[:,~df.columns.isin(string_columns)] = df.loc[:,~df.columns.isin(string_columns)].fillna(0)\n",
        "    df.loc[:,~df.columns.isin(string_columns)] = df.loc[:,~df.columns.isin(string_columns)].astype(int)\n",
        "\n",
        "    # Fill the remaining columns with b to represent they were left as blank\n",
        "    df.fillna('b',inplace=True)\n",
        "\n",
        "    # Create list of categorical columns\n",
        "    categorical_features = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
        "\n",
        "    # Remove the target question from the list of categorical columns\n",
        "    for target in targets:\n",
        "        if target in categorical_features:\n",
        "            categorical_features.remove(target)\n",
        "\n",
        "    # Split the answers in P4_4 and keep only the first word\n",
        "    df['P4_4'] = df['P4_4'].str.split().str.get(0)\n",
        "\n",
        "    # Bucket the P4_4 answers depending on their frequency \n",
        "    ## Create a dataframe to obtain the frequency of each answer for question P4_4\n",
        "    answer_freq = pd.DataFrame(\n",
        "    {\n",
        "    'NAME':df['P4_4'].value_counts().index.tolist(),\n",
        "    'COUNT':list(df['P4_4'].value_counts())\n",
        "    })\n",
        "\n",
        "    # Replace all answers that appeared less than 6 times in the dataset with Other\n",
        "    for answer in list(answer_freq.loc[(answer_freq['COUNT']<6)]['NAME']):\n",
        "      df['P4_4'] =df['P4_4'].replace(answer,\"Other\")\n",
        "    \n",
        "    # Replace all answers with a length equal or less than 3 in the dataset with Other\n",
        "    for answer in list(answer_freq['NAME']):\n",
        "      if len(answer)<=3:\n",
        "        df['P4_4'] =df['P4_4'].replace(answer,\"Other\")\n",
        "\n",
        "    # Set the categorical features dtype as string\n",
        "    df[categorical_features].apply(lambda x: x.astype(str))\n",
        "\n",
        "    # Enconde the categorical features\n",
        "    encode_df = pd.get_dummies(df, columns=categorical_features, dtype=float)\n",
        "\n",
        "    # Create the dataset for each question\n",
        "    for target in targets:\n",
        "        # Drop the rows where the target answers are blank\n",
        "        df_X = encode_df.loc[encode_df[target] != 0].drop(columns=targets)\n",
        "        df_y = encode_df.loc[encode_df[target] != 0,[target]]\n",
        "        # Create nested dictionary for the target question\n",
        "        df_X_y_dict[target] = {}\n",
        "        # Store the X and y datasets that will be used with the random forest model for the key question\n",
        "        df_X_y_dict[target]['X'] = df_X\n",
        "        df_X_y_dict[target]['y'] = df_y\n",
        "\n",
        "    return df_X_y_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c1c2e7d",
      "metadata": {
        "id": "6c1c2e7d"
      },
      "outputs": [],
      "source": [
        "# Datasets for each target question\n",
        "dataset_dictionary = DataFrame_X_y_split(df_copy, target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dictionary['P10_8_1']['X']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ULCv6TgHbimk",
        "outputId": "bc4b671a-425f-45b0-e7f8-f329c987b0a9"
      },
      "id": "ULCv6TgHbimk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       EDAD  NIV  P1_1  P1_2  P1_2_A  P1_3  P1_4_1  P1_4_2  P1_4_3  P1_4_4  \\\n",
              "0        45   11     3     3       5    15       1       1       1       2   \n",
              "1        31    4     3     2       3     5       1       1       2       2   \n",
              "2        27    4     3     1       1     3       2       1       2       2   \n",
              "3        25   10     3     1       3     6       2       1       1       2   \n",
              "6        29    2     2     2       4     6       1       1       2       2   \n",
              "...     ...  ...   ...   ...     ...   ...     ...     ...     ...     ...   \n",
              "20942    25    3     2     2       3     4       1       1       2       2   \n",
              "20943    33   10     3     2       5    19       1       1       1       2   \n",
              "20944    33   10     2     2       5    10       1       1       2       2   \n",
              "20945    35    2     2     3       4     6       1       1       1       1   \n",
              "20946    31    3     2     2       3     4       2       1       2       1   \n",
              "\n",
              "       ...  P10_7_2.0  P10_7_3.0  P10_7_4.0  P10_7_5.0  P10_7_6.0  P10_7_7.0  \\\n",
              "0      ...        0.0        0.0        0.0        0.0        1.0        0.0   \n",
              "1      ...        0.0        0.0        0.0        0.0        0.0        0.0   \n",
              "2      ...        0.0        0.0        0.0        0.0        1.0        0.0   \n",
              "3      ...        0.0        0.0        0.0        0.0        1.0        0.0   \n",
              "6      ...        0.0        0.0        0.0        1.0        0.0        0.0   \n",
              "...    ...        ...        ...        ...        ...        ...        ...   \n",
              "20942  ...        1.0        0.0        0.0        0.0        0.0        0.0   \n",
              "20943  ...        0.0        0.0        0.0        0.0        1.0        0.0   \n",
              "20944  ...        0.0        0.0        0.0        0.0        0.0        1.0   \n",
              "20945  ...        0.0        0.0        0.0        0.0        0.0        1.0   \n",
              "20946  ...        0.0        0.0        0.0        1.0        0.0        0.0   \n",
              "\n",
              "       P10_7_8.0  P10_7_9.0  P10_7_10.0  P10_7_b  \n",
              "0            0.0        0.0         0.0      0.0  \n",
              "1            0.0        0.0         0.0      0.0  \n",
              "2            0.0        0.0         0.0      0.0  \n",
              "3            0.0        0.0         0.0      0.0  \n",
              "6            0.0        0.0         0.0      0.0  \n",
              "...          ...        ...         ...      ...  \n",
              "20942        0.0        0.0         0.0      0.0  \n",
              "20943        0.0        0.0         0.0      0.0  \n",
              "20944        0.0        0.0         0.0      0.0  \n",
              "20945        0.0        0.0         0.0      0.0  \n",
              "20946        0.0        0.0         0.0      0.0  \n",
              "\n",
              "[19322 rows x 589 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa535598-fd52-47b2-acc5-9c1bdab6854d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EDAD</th>\n",
              "      <th>NIV</th>\n",
              "      <th>P1_1</th>\n",
              "      <th>P1_2</th>\n",
              "      <th>P1_2_A</th>\n",
              "      <th>P1_3</th>\n",
              "      <th>P1_4_1</th>\n",
              "      <th>P1_4_2</th>\n",
              "      <th>P1_4_3</th>\n",
              "      <th>P1_4_4</th>\n",
              "      <th>...</th>\n",
              "      <th>P10_7_2.0</th>\n",
              "      <th>P10_7_3.0</th>\n",
              "      <th>P10_7_4.0</th>\n",
              "      <th>P10_7_5.0</th>\n",
              "      <th>P10_7_6.0</th>\n",
              "      <th>P10_7_7.0</th>\n",
              "      <th>P10_7_8.0</th>\n",
              "      <th>P10_7_9.0</th>\n",
              "      <th>P10_7_10.0</th>\n",
              "      <th>P10_7_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20942</th>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20943</th>\n",
              "      <td>33</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20944</th>\n",
              "      <td>33</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20945</th>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20946</th>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19322 rows × 589 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa535598-fd52-47b2-acc5-9c1bdab6854d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa535598-fd52-47b2-acc5-9c1bdab6854d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa535598-fd52-47b2-acc5-9c1bdab6854d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Clustered_NN_Classifier(key, dict_X, dict_y, Clustered_NN_Results = {}):\n",
        "    # Create a copy of the X and y datasets to prevent modifications in the original dataset\n",
        "    X = dict_X.copy()\n",
        "    y = dict_y.copy()\n",
        "    # Create list of columns that contain a survey answer except for the marital status question\n",
        "    survey_answers = [x for x in X.columns if not re.search(\"P3_8\",x) if not re.search(\"P10_7\",x) if re.search(\"P\\d\",x)]\n",
        "    # Create a dataframe that only has the survey answers columns\n",
        "    survey_df = X[survey_answers]\n",
        "    #===========================================================================\n",
        "    # Create clustering instance\n",
        "    #agg = AgglomerativeClustering(n_clusters=18)\n",
        "    # Fit Data to model\n",
        "    #model = agg.fit(survey_df.values)\n",
        "    # Drop the clustered columns from the X dataset\n",
        "    #X = X.drop(columns=survey_answers)\n",
        "    # Add the cluster labels to the dataset\n",
        "    #X['Group'] = model.labels_\n",
        "    #===========================================================================\n",
        "    # Create gower distance matrix\n",
        "    distance_matrix = gower.gower_matrix(survey_df)\n",
        "    # Configuring the parameters of the clustering algorithm\n",
        "    dbscan_cluster = DBSCAN(eps=0.1, \n",
        "                        min_samples=2, \n",
        "                        metric=\"precomputed\")\n",
        "    # Fitting the clustering algorithm\n",
        "    dbscan_cluster.fit(distance_matrix)\n",
        "    # Drop the clustered columns from the X dataset\n",
        "    X = X.drop(columns=survey_answers)\n",
        "    # Add the cluster labels to the dataset\n",
        "    X['Group'] = dbscan_cluster.labels_\n",
        "    # Change the y labels from 1 and 2 to 0 and 1 respectively\n",
        "    y.loc[y[key] == 1,key] = 0\n",
        "    y.loc[y[key] == 2,key] = 1\n",
        "    # Calculate the count of 0s and 1s\n",
        "    pos, neg = np.bincount(y[key])\n",
        "    # Calculate the count of values in y\n",
        "    total = neg + pos\n",
        "    # Calculate the class weight\n",
        "    weight_for_0 = (10 / pos) * (total)\n",
        "    weight_for_1 = (1 / neg) * (total)\n",
        "    # Create the class weight dictionary\n",
        "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "    # Grab the y information from the target dataset\n",
        "    y = y.astype('int').values\n",
        "    # Create the train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, random_state=18, stratify=y)\n",
        "    # Create a scaler instance\n",
        "    scaler = StandardScaler()\n",
        "    # Train the standard scaler using the X_train data\n",
        "    X_scaler = scaler.fit(X_train)\n",
        "    # Scale the X training data\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    # Scale the X test data\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    # Define the number of input features and hidden nodes for each layer.\n",
        "    number_input_features = len(X_train[0])\n",
        "    hidden_nodes_layer1 = 140\n",
        "    hidden_nodes_layer2 = 100\n",
        "    hidden_nodes_layer3 = 40\n",
        "    # Create instance of the neural network\n",
        "    nn = tf.keras.models.Sequential()\n",
        "    # First hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"swish\"))\n",
        "    # Second hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "    # Third hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"swish\"))\n",
        "    # Output layer\n",
        "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the model\n",
        "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    # Train the model \n",
        "    fit_model = nn.fit(X_train_scaled,y_train,epochs=120,class_weight=class_weight)\n",
        "    # Predict the results for the target question\n",
        "    predictions = nn.predict(X_test_scaled).ravel()\n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "    # ----------------------------------------------------\n",
        "    # REFERENCE https://towardsdatascience.com/optimal-threshold-for-imbalanced-classification-5884e870c293\n",
        "    # ----------------------------------------------------\n",
        "    # Calculate the G-Mean\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(gmean)\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "    print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
        "    print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "    # plot the roc curve for the model\n",
        "    pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "    pyplot.plot(fpr, tpr, marker='.', label='Neural Network')\n",
        "    pyplot.plot(fprOpt, tprOpt, marker='*', label='Optimal Value')\n",
        "    # axis labels\n",
        "    pyplot.xlabel('False Positive Rate')\n",
        "    pyplot.ylabel('True Positive Rate')\n",
        "    pyplot.legend()\n",
        "    # show the plot\n",
        "    pyplot.show()\n",
        "    # Convert predictions to 0 or 1 according to the optimal threshold\n",
        "    threshold = thresholdOpt\n",
        "    # Label predictions using the threshold\n",
        "    binary_predictions = (predictions >= threshold).astype(int)\n",
        "    # Calculating the confusion matrix.\n",
        "    cm = confusion_matrix(y_test, binary_predictions)\n",
        "    # Evaluate the model using the test data\n",
        "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "    # Store the results results\n",
        "    Clustered_NN_Results[key] = {}\n",
        "    Clustered_NN_Results[key]['Predictions'] = binary_predictions\n",
        "    Clustered_NN_Results[key][\"Confusion Matrix\"] = cm\n",
        "    Clustered_NN_Results[key][\"Accuracy Score\"] = model_accuracy\n",
        "    Clustered_NN_Results[key][\"Classification Report\"] = classification_report(y_test, binary_predictions, target_names=['Class 1', 'Class 2'])    \n",
        "    return Clustered_NN_Results"
      ],
      "metadata": {
        "id": "v_c_Yktul6DG"
      },
      "id": "v_c_Yktul6DG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Clustered_NN_Results = Clustered_NN_Classifier('P10_8_1',dataset_dictionary['P10_8_1']['X'],dataset_dictionary['P10_8_1']['y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g9QVdc89jR7A",
        "outputId": "14904205-970d-4eef-a160-f098b29f136f"
      },
      "id": "g9QVdc89jR7A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 3.5884 - accuracy: 0.0796\n",
            "Epoch 2/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 3.2435 - accuracy: 0.0817\n",
            "Epoch 3/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 3.1931 - accuracy: 0.0966\n",
            "Epoch 4/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.1473 - accuracy: 0.1092\n",
            "Epoch 5/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.0993 - accuracy: 0.1247\n",
            "Epoch 6/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 3.0710 - accuracy: 0.1431\n",
            "Epoch 7/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.0195 - accuracy: 0.1498\n",
            "Epoch 8/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.9740 - accuracy: 0.1747\n",
            "Epoch 9/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.9457 - accuracy: 0.1830\n",
            "Epoch 10/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.8818 - accuracy: 0.1951\n",
            "Epoch 11/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.8218 - accuracy: 0.2135\n",
            "Epoch 12/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.8267 - accuracy: 0.2288\n",
            "Epoch 13/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.7291 - accuracy: 0.2397\n",
            "Epoch 14/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.6645 - accuracy: 0.2702\n",
            "Epoch 15/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.6094 - accuracy: 0.2882\n",
            "Epoch 16/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.5681 - accuracy: 0.3011\n",
            "Epoch 17/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.5358 - accuracy: 0.3125\n",
            "Epoch 18/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.5025 - accuracy: 0.3210\n",
            "Epoch 19/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.4667 - accuracy: 0.3353\n",
            "Epoch 20/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3760 - accuracy: 0.3539\n",
            "Epoch 21/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3562 - accuracy: 0.3677\n",
            "Epoch 22/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3072 - accuracy: 0.3825\n",
            "Epoch 23/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.2483 - accuracy: 0.3996\n",
            "Epoch 24/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.2077 - accuracy: 0.4155\n",
            "Epoch 25/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1593 - accuracy: 0.4287\n",
            "Epoch 26/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1084 - accuracy: 0.4397\n",
            "Epoch 27/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.0493 - accuracy: 0.4603\n",
            "Epoch 28/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.0276 - accuracy: 0.4733\n",
            "Epoch 29/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.0198 - accuracy: 0.4737\n",
            "Epoch 30/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.9626 - accuracy: 0.4949\n",
            "Epoch 31/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.9235 - accuracy: 0.5016\n",
            "Epoch 32/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.9143 - accuracy: 0.5083\n",
            "Epoch 33/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.8724 - accuracy: 0.5238\n",
            "Epoch 34/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.8237 - accuracy: 0.5349\n",
            "Epoch 35/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.8180 - accuracy: 0.5381\n",
            "Epoch 36/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.7478 - accuracy: 0.5529\n",
            "Epoch 37/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.7797 - accuracy: 0.5525\n",
            "Epoch 38/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.7258 - accuracy: 0.5659\n",
            "Epoch 39/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7594 - accuracy: 0.5608\n",
            "Epoch 40/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7399 - accuracy: 0.5660\n",
            "Epoch 41/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6457 - accuracy: 0.5866\n",
            "Epoch 42/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6675 - accuracy: 0.5880\n",
            "Epoch 43/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6067 - accuracy: 0.5920\n",
            "Epoch 44/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6009 - accuracy: 0.6017\n",
            "Epoch 45/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.6039 - accuracy: 0.6060\n",
            "Epoch 46/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.7288 - accuracy: 0.5717\n",
            "Epoch 47/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.5967 - accuracy: 0.5994\n",
            "Epoch 48/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.5448 - accuracy: 0.6146\n",
            "Epoch 49/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.5338 - accuracy: 0.6180\n",
            "Epoch 50/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.5003 - accuracy: 0.6284\n",
            "Epoch 51/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4941 - accuracy: 0.6292\n",
            "Epoch 52/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4712 - accuracy: 0.6395\n",
            "Epoch 53/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.5315 - accuracy: 0.6331\n",
            "Epoch 54/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4733 - accuracy: 0.6342\n",
            "Epoch 55/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4507 - accuracy: 0.6479\n",
            "Epoch 56/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4780 - accuracy: 0.6463\n",
            "Epoch 57/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4659 - accuracy: 0.6387\n",
            "Epoch 58/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4079 - accuracy: 0.6578\n",
            "Epoch 59/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3935 - accuracy: 0.6583\n",
            "Epoch 60/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.3444 - accuracy: 0.6777\n",
            "Epoch 61/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3950 - accuracy: 0.6699\n",
            "Epoch 62/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3904 - accuracy: 0.6654\n",
            "Epoch 63/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3471 - accuracy: 0.6739\n",
            "Epoch 64/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3424 - accuracy: 0.6773\n",
            "Epoch 65/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3215 - accuracy: 0.6828\n",
            "Epoch 66/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3709 - accuracy: 0.6732\n",
            "Epoch 67/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3446 - accuracy: 0.6748\n",
            "Epoch 68/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2680 - accuracy: 0.6921\n",
            "Epoch 69/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2678 - accuracy: 0.6943\n",
            "Epoch 70/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.3620 - accuracy: 0.6852\n",
            "Epoch 71/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3421 - accuracy: 0.6785\n",
            "Epoch 72/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2725 - accuracy: 0.6877\n",
            "Epoch 73/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2525 - accuracy: 0.7034\n",
            "Epoch 74/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3023 - accuracy: 0.6937\n",
            "Epoch 75/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2740 - accuracy: 0.6984\n",
            "Epoch 76/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2267 - accuracy: 0.7017\n",
            "Epoch 77/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1765 - accuracy: 0.7173\n",
            "Epoch 78/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2397 - accuracy: 0.7076\n",
            "Epoch 79/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2421 - accuracy: 0.7073\n",
            "Epoch 80/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1714 - accuracy: 0.7240\n",
            "Epoch 81/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1680 - accuracy: 0.7271\n",
            "Epoch 82/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1143 - accuracy: 0.7319\n",
            "Epoch 83/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1374 - accuracy: 0.7383\n",
            "Epoch 84/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1946 - accuracy: 0.7266\n",
            "Epoch 85/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2151 - accuracy: 0.7146\n",
            "Epoch 86/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1705 - accuracy: 0.7296\n",
            "Epoch 87/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1438 - accuracy: 0.7327\n",
            "Epoch 88/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2241 - accuracy: 0.7222\n",
            "Epoch 89/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1132 - accuracy: 0.7360\n",
            "Epoch 90/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0635 - accuracy: 0.7483\n",
            "Epoch 91/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1214 - accuracy: 0.7389\n",
            "Epoch 92/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0747 - accuracy: 0.7474\n",
            "Epoch 93/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1143 - accuracy: 0.7453\n",
            "Epoch 94/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1089 - accuracy: 0.7432\n",
            "Epoch 95/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1986 - accuracy: 0.7307\n",
            "Epoch 96/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1887 - accuracy: 0.7215\n",
            "Epoch 97/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1038 - accuracy: 0.7432\n",
            "Epoch 98/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0744 - accuracy: 0.7528\n",
            "Epoch 99/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0280 - accuracy: 0.7596\n",
            "Epoch 100/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.7652\n",
            "Epoch 101/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9816 - accuracy: 0.7719\n",
            "Epoch 102/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0818 - accuracy: 0.7514\n",
            "Epoch 103/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0406 - accuracy: 0.7619\n",
            "Epoch 104/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0402 - accuracy: 0.7621\n",
            "Epoch 105/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0819 - accuracy: 0.7584\n",
            "Epoch 106/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0743 - accuracy: 0.7535\n",
            "Epoch 107/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0769 - accuracy: 0.7581\n",
            "Epoch 108/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0899 - accuracy: 0.7523\n",
            "Epoch 109/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9967 - accuracy: 0.7701\n",
            "Epoch 110/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0111 - accuracy: 0.7726\n",
            "Epoch 111/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0408 - accuracy: 0.7649\n",
            "Epoch 112/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0715 - accuracy: 0.7610\n",
            "Epoch 113/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0022 - accuracy: 0.7748\n",
            "Epoch 114/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0122 - accuracy: 0.7717\n",
            "Epoch 115/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0386 - accuracy: 0.7690\n",
            "Epoch 116/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9966 - accuracy: 0.7739\n",
            "Epoch 117/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9348 - accuracy: 0.7854\n",
            "Epoch 118/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9340 - accuracy: 0.7913\n",
            "Epoch 119/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.7781\n",
            "Epoch 120/120\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 1.0864 - accuracy: 0.7654\n",
            "151/151 [==============================] - 0s 2ms/step\n",
            "Best Threshold: 0.9950000047683716 with G-Mean: 0.543\n",
            "FPR: 0.3689, TPR: 0.4672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 - 0s - loss: 1.4214 - accuracy: 0.6674 - 492ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Classification Report'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7nQKWZJjSE0",
        "outputId": "944c5e85-ceb5-4629-addd-415f754c68a5"
      },
      "id": "Y7nQKWZJjSE0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.09      0.52      0.15       347\n",
            "     Class 2       0.94      0.59      0.73      4484\n",
            "\n",
            "    accuracy                           0.59      4831\n",
            "   macro avg       0.51      0.55      0.44      4831\n",
            "weighted avg       0.88      0.59      0.68      4831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Confusion Matrix'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCcacT3ojSI7",
        "outputId": "c8c57e6a-c8f6-4614-955c-7df4419741e1"
      },
      "id": "UCcacT3ojSI7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 179  168]\n",
            " [1834 2650]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Clustered_NN_Classifier(key, dict_X, dict_y, Clustered_NN_Results = {}):\n",
        "    # Create a copy of the X and y datasets to prevent modifications in the original dataset\n",
        "    X = dict_X.copy()\n",
        "    y = dict_y.copy()\n",
        "    # Create list of columns that contain a survey answer except for the marital status question\n",
        "    table_sections = ['P1','P2','P3','P4','P10']\n",
        "    section_features = {}\n",
        "    for table in table_sections:\n",
        "      section_features[table] = [x for x in X.columns if not re.search(\"P3_8\",x) if not re.search(\"P10_7\",x) if re.search(f'{table}_',x)]\n",
        "      # Create a dataframe that only has the survey answers columns\n",
        "      survey_df = X[section_features[table]]\n",
        "      # Create gower distance matrix\n",
        "      distance_matrix = gower.gower_matrix(survey_df)\n",
        "      # Configuring the parameters of the clustering algorithm\n",
        "      dbscan_cluster = DBSCAN(eps=0.1, \n",
        "                          min_samples=2, \n",
        "                          metric=\"precomputed\")\n",
        "      # Fitting the clustering algorithm\n",
        "      dbscan_cluster.fit(distance_matrix)\n",
        "      # Add the cluster labels to the dataset\n",
        "      X[f'{table}_Group'] = dbscan_cluster.labels_\n",
        "      # Drop the columns from the original cluster\n",
        "      X = X.drop(columns=section_features[table])\n",
        "      # Enconde the clusters \n",
        "      X = pd.get_dummies(X, columns=[f'{table}_Group'])\n",
        "    # Change the y labels from 1 and 2 to 0 and 1 respectively\n",
        "    y.loc[y[key] == 1,key] = 0\n",
        "    y.loc[y[key] == 2,key] = 1\n",
        "    # Calculate the count of 0s and 1s\n",
        "    pos, neg = np.bincount(y[key])\n",
        "    # Calculate the count of values in y\n",
        "    total = neg + pos\n",
        "    # Calculate the class weight\n",
        "    weight_for_0 = (10 / pos) * (total)\n",
        "    weight_for_1 = (1 / neg) * (total)\n",
        "    # Create the class weight dictionary\n",
        "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "    # Grab the y information from the target dataset\n",
        "    y = y.astype('int').values\n",
        "    # Create the train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, random_state=18, stratify=y)\n",
        "    # Create a scaler instance\n",
        "    scaler = StandardScaler()\n",
        "    # Train the standard scaler using the X_train data\n",
        "    X_scaler = scaler.fit(X_train)\n",
        "    # Scale the X training data\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    # Scale the X test data\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    # Define the number of input features and hidden nodes for each layer.\n",
        "    number_input_features = len(X_train[0])\n",
        "    hidden_nodes_layer1 = 140\n",
        "    hidden_nodes_layer2 = 100\n",
        "    hidden_nodes_layer3 = 40\n",
        "    # Create instance of the neural network\n",
        "    nn = tf.keras.models.Sequential()\n",
        "    # First hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"swish\"))\n",
        "    # Second hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "    # Third hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"swish\"))\n",
        "    # Output layer\n",
        "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the model\n",
        "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    # Train the model \n",
        "    fit_model = nn.fit(X_train_scaled,y_train,epochs=120,class_weight=class_weight)\n",
        "    # Predict the results for the target question\n",
        "    predictions = nn.predict(X_test_scaled).ravel()\n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "    # ----------------------------------------------------\n",
        "    # REFERENCE https://towardsdatascience.com/optimal-threshold-for-imbalanced-classification-5884e870c293\n",
        "    # ----------------------------------------------------\n",
        "    # Calculate the G-Mean\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(gmean)\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "    print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
        "    print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "    # plot the roc curve for the model\n",
        "    pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "    pyplot.plot(fpr, tpr, marker='.', label='Neural Network')\n",
        "    pyplot.plot(fprOpt, tprOpt, marker='*', label='Optimal Value')\n",
        "    # axis labels\n",
        "    pyplot.xlabel('False Positive Rate')\n",
        "    pyplot.ylabel('True Positive Rate')\n",
        "    pyplot.legend()\n",
        "    # show the plot\n",
        "    pyplot.show()\n",
        "    # Convert predictions to 0 or 1 according to the optimal threshold\n",
        "    threshold = thresholdOpt\n",
        "    # Label predictions using the threshold\n",
        "    binary_predictions = (predictions >= threshold).astype(int)\n",
        "    # Calculating the confusion matrix.\n",
        "    cm = confusion_matrix(y_test, binary_predictions)\n",
        "    # Evaluate the model using the test data\n",
        "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "    # Store the results results\n",
        "    Clustered_NN_Results[key] = {}\n",
        "    Clustered_NN_Results[key]['Predictions'] = binary_predictions\n",
        "    Clustered_NN_Results[key][\"Confusion Matrix\"] = cm\n",
        "    Clustered_NN_Results[key][\"Accuracy Score\"] = model_accuracy\n",
        "    Clustered_NN_Results[key][\"Classification Report\"] = classification_report(y_test, binary_predictions, target_names=['Class 1', 'Class 2'])    \n",
        "    return Clustered_NN_Results"
      ],
      "metadata": {
        "id": "G-lwg8eXZhzv"
      },
      "id": "G-lwg8eXZhzv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Clustered_NN_Results = Clustered_NN_Classifier('P10_8_1',dataset_dictionary['P10_8_1']['X'],dataset_dictionary['P10_8_1']['y'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JJDJ1_9Hjs_S",
        "outputId": "a2abb1d6-20a8-4754-a2ac-c66845fced71"
      },
      "id": "JJDJ1_9Hjs_S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 3.4521 - accuracy: 0.0782\n",
            "Epoch 2/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.2162 - accuracy: 0.0823\n",
            "Epoch 3/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.1534 - accuracy: 0.0957\n",
            "Epoch 4/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.1066 - accuracy: 0.1112\n",
            "Epoch 5/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 3.0335 - accuracy: 0.1360\n",
            "Epoch 6/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.9182 - accuracy: 0.1798\n",
            "Epoch 7/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.8714 - accuracy: 0.2034\n",
            "Epoch 8/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.7831 - accuracy: 0.2241\n",
            "Epoch 9/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.6558 - accuracy: 0.2702\n",
            "Epoch 10/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.5996 - accuracy: 0.2779\n",
            "Epoch 11/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.4847 - accuracy: 0.3165\n",
            "Epoch 12/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3974 - accuracy: 0.3411\n",
            "Epoch 13/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3254 - accuracy: 0.3653\n",
            "Epoch 14/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.2495 - accuracy: 0.3814\n",
            "Epoch 15/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1388 - accuracy: 0.4175\n",
            "Epoch 16/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.0969 - accuracy: 0.4375\n",
            "Epoch 17/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.0246 - accuracy: 0.4585\n",
            "Epoch 18/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.0227 - accuracy: 0.4586\n",
            "Epoch 19/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.9027 - accuracy: 0.4918\n",
            "Epoch 20/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.8045 - accuracy: 0.5220\n",
            "Epoch 21/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.7395 - accuracy: 0.5428\n",
            "Epoch 22/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6961 - accuracy: 0.5611\n",
            "Epoch 23/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.6492 - accuracy: 0.5768\n",
            "Epoch 24/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.5355 - accuracy: 0.6049\n",
            "Epoch 25/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4960 - accuracy: 0.6164\n",
            "Epoch 26/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4179 - accuracy: 0.6401\n",
            "Epoch 27/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4508 - accuracy: 0.6369\n",
            "Epoch 28/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4095 - accuracy: 0.6444\n",
            "Epoch 29/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3689 - accuracy: 0.6590\n",
            "Epoch 30/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3678 - accuracy: 0.6643\n",
            "Epoch 31/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3905 - accuracy: 0.6666\n",
            "Epoch 32/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3049 - accuracy: 0.6797\n",
            "Epoch 33/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2617 - accuracy: 0.6974\n",
            "Epoch 34/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1836 - accuracy: 0.7126\n",
            "Epoch 35/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1941 - accuracy: 0.7176\n",
            "Epoch 36/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2500 - accuracy: 0.7080\n",
            "Epoch 37/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2083 - accuracy: 0.7156\n",
            "Epoch 38/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1249 - accuracy: 0.7340\n",
            "Epoch 39/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.7570\n",
            "Epoch 40/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.7681\n",
            "Epoch 41/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0268 - accuracy: 0.7663\n",
            "Epoch 42/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0469 - accuracy: 0.7661\n",
            "Epoch 43/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0801 - accuracy: 0.7572\n",
            "Epoch 44/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0435 - accuracy: 0.7654\n",
            "Epoch 45/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1609 - accuracy: 0.7447\n",
            "Epoch 46/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2637 - accuracy: 0.7378\n",
            "Epoch 47/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1676 - accuracy: 0.7405\n",
            "Epoch 48/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9968 - accuracy: 0.7704\n",
            "Epoch 49/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9054 - accuracy: 0.7919\n",
            "Epoch 50/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8488 - accuracy: 0.8061\n",
            "Epoch 51/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8416 - accuracy: 0.8083\n",
            "Epoch 52/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8640 - accuracy: 0.8117\n",
            "Epoch 53/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9978 - accuracy: 0.7917\n",
            "Epoch 54/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9547 - accuracy: 0.7921\n",
            "Epoch 55/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9316 - accuracy: 0.7937\n",
            "Epoch 56/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9619 - accuracy: 0.7967\n",
            "Epoch 57/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.7964\n",
            "Epoch 58/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9563 - accuracy: 0.8055\n",
            "Epoch 59/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8997 - accuracy: 0.8063\n",
            "Epoch 60/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8625 - accuracy: 0.8110\n",
            "Epoch 61/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8134 - accuracy: 0.8220\n",
            "Epoch 62/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8374 - accuracy: 0.8226\n",
            "Epoch 63/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8384 - accuracy: 0.8271\n",
            "Epoch 64/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8228 - accuracy: 0.8217\n",
            "Epoch 65/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8266 - accuracy: 0.8280\n",
            "Epoch 66/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8628 - accuracy: 0.8144\n",
            "Epoch 67/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.8380\n",
            "Epoch 68/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7005 - accuracy: 0.8477\n",
            "Epoch 69/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7193 - accuracy: 0.8416\n",
            "Epoch 70/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.8278\n",
            "Epoch 71/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9487 - accuracy: 0.8017\n",
            "Epoch 72/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9303 - accuracy: 0.8192\n",
            "Epoch 73/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7239 - accuracy: 0.8446\n",
            "Epoch 74/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6986 - accuracy: 0.8501\n",
            "Epoch 75/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6808 - accuracy: 0.8559\n",
            "Epoch 76/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7192 - accuracy: 0.8466\n",
            "Epoch 77/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7311 - accuracy: 0.8478\n",
            "Epoch 78/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8260 - accuracy: 0.8282\n",
            "Epoch 79/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8938 - accuracy: 0.8153\n",
            "Epoch 80/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8585 - accuracy: 0.8222\n",
            "Epoch 81/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8024 - accuracy: 0.8343\n",
            "Epoch 82/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7832 - accuracy: 0.8391\n",
            "Epoch 83/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7174 - accuracy: 0.8440\n",
            "Epoch 84/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6559 - accuracy: 0.8621\n",
            "Epoch 85/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6336 - accuracy: 0.8602\n",
            "Epoch 86/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5838 - accuracy: 0.8755\n",
            "Epoch 87/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5839 - accuracy: 0.8760\n",
            "Epoch 88/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6359 - accuracy: 0.8709\n",
            "Epoch 89/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7027 - accuracy: 0.8594\n",
            "Epoch 90/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8479 - accuracy: 0.8431\n",
            "Epoch 91/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7952 - accuracy: 0.8390\n",
            "Epoch 92/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7699 - accuracy: 0.8438\n",
            "Epoch 93/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7040 - accuracy: 0.8564\n",
            "Epoch 94/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.8678\n",
            "Epoch 95/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.5604 - accuracy: 0.8790\n",
            "Epoch 96/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.8769\n",
            "Epoch 97/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6190 - accuracy: 0.8744\n",
            "Epoch 98/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7313 - accuracy: 0.8585\n",
            "Epoch 99/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.8475\n",
            "Epoch 100/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6692 - accuracy: 0.8609\n",
            "Epoch 101/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6850 - accuracy: 0.8578\n",
            "Epoch 102/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6679 - accuracy: 0.8630\n",
            "Epoch 103/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7448 - accuracy: 0.8565\n",
            "Epoch 104/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7549 - accuracy: 0.8445\n",
            "Epoch 105/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6008 - accuracy: 0.8735\n",
            "Epoch 106/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.8867\n",
            "Epoch 107/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5157 - accuracy: 0.8923\n",
            "Epoch 108/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6045 - accuracy: 0.8778\n",
            "Epoch 109/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5598 - accuracy: 0.8811\n",
            "Epoch 110/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.5820 - accuracy: 0.8882\n",
            "Epoch 111/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.8734\n",
            "Epoch 112/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5699 - accuracy: 0.8866\n",
            "Epoch 113/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7878 - accuracy: 0.8543\n",
            "Epoch 114/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0333 - accuracy: 0.8259\n",
            "Epoch 115/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8575 - accuracy: 0.8300\n",
            "Epoch 116/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7610 - accuracy: 0.8534\n",
            "Epoch 117/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.8768\n",
            "Epoch 118/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.8938\n",
            "Epoch 119/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4765 - accuracy: 0.8952\n",
            "Epoch 120/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.9010\n",
            "151/151 [==============================] - 0s 1ms/step\n",
            "Best Threshold: 0.9887999892234802 with G-Mean: 0.5479\n",
            "FPR: 0.4784, TPR: 0.5756\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 - 0s - loss: 1.1625 - accuracy: 0.7626 - 499ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Classification Report'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpcdt1OpjtHQ",
        "outputId": "2da1ab0e-bcc2-45aa-ab45-84dbddcbdc84"
      },
      "id": "gpcdt1OpjtHQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.09      0.52      0.15       347\n",
            "     Class 2       0.94      0.58      0.71      4484\n",
            "\n",
            "    accuracy                           0.57      4831\n",
            "   macro avg       0.51      0.55      0.43      4831\n",
            "weighted avg       0.88      0.57      0.67      4831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Confusion Matrix'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40QSIPfLjtLN",
        "outputId": "8f923282-0fbd-453a-a5c2-0500c72bb276"
      },
      "id": "40QSIPfLjtLN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 181  166]\n",
            " [1904 2580]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Clustered_NN_Classifier(key, dict_X, dict_y, Clustered_NN_Results = {}):\n",
        "    # Create a copy of the X and y datasets to prevent modifications in the original dataset\n",
        "    X = dict_X.copy()\n",
        "    y = dict_y.copy()\n",
        "    # Create list of columns that contain a survey answer except for the marital status question\n",
        "    table_sections = ['P1','P2','P3','P4','P10']\n",
        "    section_features = {}\n",
        "    for table in table_sections:\n",
        "      section_features[table] = [x for x in X.columns if not re.search(\"P3_8\",x) if not re.search(\"P10_7\",x) if re.search(f'{table}_',x)]\n",
        "      # Create a dataframe that only has the survey answers columns\n",
        "      survey_df = X[section_features[table]]\n",
        "      # Create gower distance matrix\n",
        "      distance_matrix = gower.gower_matrix(survey_df)\n",
        "      # Configuring the parameters of the clustering algorithm\n",
        "      model_complete = AgglomerativeClustering(n_clusters=10, linkage='complete', affinity='precomputed')\n",
        "      # fitting the distance matrix\n",
        "      clusters_complete = model_complete.fit_predict(distance_matrix)\n",
        "      # Add the cluster labels to the dataset\n",
        "      X[f'{table}_Group'] = clusters_complete\n",
        "      # Drop the columns from the original cluster\n",
        "      X = X.drop(columns=section_features[table])\n",
        "      # Enconde the clusters \n",
        "      X = pd.get_dummies(X, columns=[f'{table}_Group'])\n",
        "    print(section_features)\n",
        "    # Change the y labels from 1 and 2 to 0 and 1 respectively\n",
        "    y.loc[y[key] == 1,key] = 0\n",
        "    y.loc[y[key] == 2,key] = 1\n",
        "    # Calculate the count of 0s and 1s\n",
        "    pos, neg = np.bincount(y[key])\n",
        "    # Calculate the count of values in y\n",
        "    total = neg + pos\n",
        "    # Calculate the class weight\n",
        "    weight_for_0 = (10 / pos) * (total)\n",
        "    weight_for_1 = (1 / neg) * (total)\n",
        "    # Create the class weight dictionary\n",
        "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "    # Grab the y information from the target dataset\n",
        "    y = y.astype('int').values\n",
        "    # Create the train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, random_state=18, stratify=y)\n",
        "    # Create a scaler instance\n",
        "    scaler = StandardScaler()\n",
        "    # Train the standard scaler using the X_train data\n",
        "    X_scaler = scaler.fit(X_train)\n",
        "    # Scale the X training data\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    # Scale the X test data\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    # Define the number of input features and hidden nodes for each layer.\n",
        "    number_input_features = len(X_train[0])\n",
        "    hidden_nodes_layer1 = 140\n",
        "    hidden_nodes_layer2 = 100\n",
        "    hidden_nodes_layer3 = 40\n",
        "    # Create instance of the neural network\n",
        "    nn = tf.keras.models.Sequential()\n",
        "    # First hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"swish\"))\n",
        "    # Second hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "    # Third hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"swish\"))\n",
        "    # Output layer\n",
        "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the model\n",
        "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    # Train the model \n",
        "    fit_model = nn.fit(X_train_scaled,y_train,epochs=120,class_weight=class_weight)\n",
        "    # Predict the results for the target question\n",
        "    predictions = nn.predict(X_test_scaled).ravel()\n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "    # ----------------------------------------------------\n",
        "    # REFERENCE https://towardsdatascience.com/optimal-threshold-for-imbalanced-classification-5884e870c293\n",
        "    # ----------------------------------------------------\n",
        "    # Calculate the G-Mean\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(gmean)\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "    print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
        "    print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "    # plot the roc curve for the model\n",
        "    pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "    pyplot.plot(fpr, tpr, marker='.', label='Neural Network')\n",
        "    pyplot.plot(fprOpt, tprOpt, marker='*', label='Optimal Value')\n",
        "    # axis labels\n",
        "    pyplot.xlabel('False Positive Rate')\n",
        "    pyplot.ylabel('True Positive Rate')\n",
        "    pyplot.legend()\n",
        "    # show the plot\n",
        "    pyplot.show()\n",
        "    # Convert predictions to 0 or 1 according to the optimal threshold\n",
        "    threshold = thresholdOpt\n",
        "    # Label predictions using the threshold\n",
        "    binary_predictions = (predictions >= threshold).astype(int)\n",
        "    # Calculating the confusion matrix.\n",
        "    cm = confusion_matrix(y_test, binary_predictions)\n",
        "    # Evaluate the model using the test data\n",
        "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "    # Store the results results\n",
        "    Clustered_NN_Results[key] = {}\n",
        "    Clustered_NN_Results[key]['Predictions'] = binary_predictions\n",
        "    Clustered_NN_Results[key][\"Confusion Matrix\"] = cm\n",
        "    Clustered_NN_Results[key][\"Accuracy Score\"] = model_accuracy\n",
        "    Clustered_NN_Results[key][\"Classification Report\"] = classification_report(y_test, binary_predictions, target_names=['Class 1', 'Class 2'])    \n",
        "    return Clustered_NN_Results"
      ],
      "metadata": {
        "id": "wnWtas7KkBLY"
      },
      "id": "wnWtas7KkBLY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Clustered_NN_Results = Clustered_NN_Classifier('P10_8_1',dataset_dictionary['P10_8_1']['X'],dataset_dictionary['P10_8_1']['y'])"
      ],
      "metadata": {
        "id": "Dmkph2pNkQKN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f7ac1f3-6350-4101-8ca8-06ed1fee90e5"
      },
      "id": "Dmkph2pNkQKN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'P1': ['P1_1', 'P1_2', 'P1_2_A', 'P1_3', 'P1_4_1', 'P1_4_2', 'P1_4_3', 'P1_4_4', 'P1_4_5', 'P1_4_6', 'P1_4_7', 'P1_4_8', 'P1_4_9', 'P1_5', 'P1_6', 'P1_7', 'P1_8', 'P1_9', 'P1_10_1_0.0', 'P1_10_1_1.0', 'P1_10_1_b', 'P1_10_2_0.0', 'P1_10_2_1.0', 'P1_10_2_b', 'P1_10_3_0.0', 'P1_10_3_1.0', 'P1_10_3_b', 'P1_10_4_0.0', 'P1_10_4_1.0', 'P1_10_4_b'], 'P2': ['P2_5', 'P2_6', 'P2_9', 'P2_10', 'P2_11', 'P2_13', 'P2_16', 'P2_8_1.0', 'P2_8_2.0', 'P2_8_b', 'P2_12_1.0', 'P2_12_2.0', 'P2_12_b', 'P2_14_1.0', 'P2_14_2.0', 'P2_14_3.0', 'P2_14_4.0', 'P2_14_5.0', 'P2_14_6.0', 'P2_14_7.0', 'P2_14_8.0', 'P2_14_9.0', 'P2_14_10.0', 'P2_14_11.0', 'P2_14_12.0', 'P2_14_99.0', 'P2_14_b', 'P2_15_1.0', 'P2_15_2.0', 'P2_15_3.0', 'P2_15_4.0', 'P2_15_5.0', 'P2_15_6.0', 'P2_15_b'], 'P3': ['P3_1', 'P3_2_1.0', 'P3_2_2.0', 'P3_2_b', 'P3_3_1.0', 'P3_3_2.0', 'P3_3_3.0', 'P3_3_4.0', 'P3_3_5.0', 'P3_3_6.0', 'P3_3_7.0', 'P3_3_b', 'P3_4_1.0', 'P3_4_2.0', 'P3_4_b', 'P3_5_1.0', 'P3_5_2.0', 'P3_5_b', 'P3_6_1.0', 'P3_6_2.0', 'P3_6_3.0', 'P3_6_4.0', 'P3_6_b', 'P3_7_1.0', 'P3_7_2.0', 'P3_7_b'], 'P4': ['P4_1', 'P4_2', 'P4_5_AB', 'P4_7_AB', 'P4_8_1', 'P4_8_2', 'P4_8_3', 'P4_8_4', 'P4_8_5', 'P4_8_6', 'P4_8_7', 'P4_9_1', 'P4_9_2', 'P4_9_3', 'P4_9_4', 'P4_9_5', 'P4_9_6', 'P4_9_7', 'P4_11', 'P4_12_1', 'P4_12_2', 'P4_12_3', 'P4_12_4', 'P4_12_5', 'P4_12_6', 'P4_12_7', 'P4_2_1_1.0', 'P4_2_1_2.0', 'P4_2_1_3.0', 'P4_2_1_8.0', 'P4_2_1_9.0', 'P4_2_1_b', 'P4_3_1.0', 'P4_3_2.0', 'P4_3_8.0', 'P4_3_9.0', 'P4_3_b', 'P4_4_ABOGADO', 'P4_4_ADMINISTRADOR', 'P4_4_ADMINISTRATIVO', 'P4_4_AGENTE', 'P4_4_AGRICULTOR', 'P4_4_AGRICULTURA', 'P4_4_ALBANIL', 'P4_4_ALBAÑIL', 'P4_4_ALBAÑIL,', 'P4_4_ALBAÑILERIA', 'P4_4_ALMACENISTA', 'P4_4_ALUMINIERO', 'P4_4_ANALISTA', 'P4_4_APICULTOR', 'P4_4_AREA', 'P4_4_ARQUITECTO', 'P4_4_ARTESANO', 'P4_4_ASESOR', 'P4_4_ASISTENTE', 'P4_4_ATENCION', 'P4_4_ATIENDE', 'P4_4_AUDITOR', 'P4_4_AUXILIAR', 'P4_4_AYUDA', 'P4_4_AYUDANTE', 'P4_4_AYUNDANTE', 'P4_4_BARBERO', 'P4_4_BODEGUERO', 'P4_4_BOMBERO', 'P4_4_CABO', 'P4_4_CAJERO', 'P4_4_CAMILLERO', 'P4_4_CAMIONERO', 'P4_4_CAMPECINO', 'P4_4_CAMPESINO', 'P4_4_CAMPO', 'P4_4_CANTINERO', 'P4_4_CAPATAZ', 'P4_4_CAPITAN', 'P4_4_CAPTURISTA', 'P4_4_CARGADOR', 'P4_4_CARNICERO', 'P4_4_CARPINTERIA', 'P4_4_CARPINTERO', 'P4_4_CARROCERO', 'P4_4_CHALAN', 'P4_4_CHEF', 'P4_4_CHOFER', 'P4_4_COBRADOR', 'P4_4_COCINERO', 'P4_4_COMERCIANTE', 'P4_4_COMERCIANTE,', 'P4_4_COMERCIANTES', 'P4_4_COMPRA', 'P4_4_CONDUCTOR', 'P4_4_CONSTRUCCION', 'P4_4_CONSTRUCTOR', 'P4_4_CONTADOR', 'P4_4_CONTRATISTA', 'P4_4_CONTRUCCION', 'P4_4_COORDINADOR', 'P4_4_CORTA', 'P4_4_CORTADOR', 'P4_4_CORTANDO', 'P4_4_CORTE', 'P4_4_COSECHA', 'P4_4_COSINERO', 'P4_4_COSTURERO', 'P4_4_CRIA', 'P4_4_CUIDA', 'P4_4_CUIDADOR', 'P4_4_CUSTODIO', 'P4_4_DENTISTA', 'P4_4_DESARROLLADOR', 'P4_4_DESCONOCE', 'P4_4_DESPACHADOR', 'P4_4_DIRECTOR', 'P4_4_DISEÑADOR', 'P4_4_DOCENTE', 'P4_4_DOCTOR', 'P4_4_DUEÑO', 'P4_4_EJECUTIVO', 'P4_4_ELABORA', 'P4_4_ELABORACION', 'P4_4_ELECTRICISTA', 'P4_4_ELECTRICO', 'P4_4_ELECTRISISTA', 'P4_4_ELECTROMECANICO', 'P4_4_EMPACADOR', 'P4_4_EMPLEADA', 'P4_4_EMPLEADO', 'P4_4_EMPRENDEDOR', 'P4_4_EMPRESARIO', 'P4_4_ENCARGADO', 'P4_4_ENFERMERO', 'P4_4_ENSAMBLADOR', 'P4_4_ENTRENADOR', 'P4_4_FABRICA', 'P4_4_FIERRERO', 'P4_4_FONTANERO', 'P4_4_FOTOGRAFO', 'P4_4_FUMIGADOR', 'P4_4_GANADERO', 'P4_4_GARROTERO', 'P4_4_GERENTE', 'P4_4_GESTOR', 'P4_4_GRANJERO', 'P4_4_GUARDIA', 'P4_4_HACE', 'P4_4_HERRERO', 'P4_4_HOJALATERO', 'P4_4_INGENIERO', 'P4_4_INSPECTOR', 'P4_4_INSTALADOR', 'P4_4_INSTRUCTOR', 'P4_4_INTENDENTE', 'P4_4_JARDINERO', 'P4_4_JEFE', 'P4_4_JORNALERO', 'P4_4_JORNALERO,', 'P4_4_LABORATORISTA', 'P4_4_LADRILLERO', 'P4_4_LAVA', 'P4_4_LAVADOR', 'P4_4_LICENCIADO', 'P4_4_LIDER', 'P4_4_LIMPIA', 'P4_4_LIMPIADOR', 'P4_4_LIMPIEZA', 'P4_4_LLANTERO', 'P4_4_MAESTRO', 'P4_4_MANEJA', 'P4_4_MANIOBRISTA', 'P4_4_MANTENIMIENTO', 'P4_4_MAQUINISTA', 'P4_4_MARIACHI', 'P4_4_MARINO', 'P4_4_MARMOLERO', 'P4_4_MATERIALISTA', 'P4_4_MECANICO', 'P4_4_MEDICO', 'P4_4_MENSAJERO', 'P4_4_MESERO', 'P4_4_MILITAR', 'P4_4_MINERO', 'P4_4_MONTA', 'P4_4_MONTACARGISTA', 'P4_4_MONTACARGUISTA', 'P4_4_MOTO', 'P4_4_MOTOTAXISTA', 'P4_4_MUSICO', 'P4_4_NEGOCIO', 'P4_4_OBRA', 'P4_4_OBRERO', 'P4_4_OFICIAL', 'P4_4_OFICINISTA', 'P4_4_OPERADOR', 'P4_4_OPERARIO', 'P4_4_ORDEÑADOR', 'P4_4_Other', 'P4_4_PANADERO', 'P4_4_PARAMEDICO', 'P4_4_PASTOR', 'P4_4_PATRON', 'P4_4_PELUQUERO', 'P4_4_PEON', 'P4_4_PEON,', 'P4_4_PERSONAL', 'P4_4_PESCADOR', 'P4_4_PESPUNTADOR', 'P4_4_PINTOR', 'P4_4_PISCA', 'P4_4_PLOMERO', 'P4_4_POLICIA', 'P4_4_PONE', 'P4_4_PREPARADOR', 'P4_4_PRODUCCION', 'P4_4_PRODUCTOR', 'P4_4_PROFESOR', 'P4_4_PROGRAMADOR', 'P4_4_PROMOTOR', 'P4_4_PROPIETARIO', 'P4_4_PSICOLOGO', 'P4_4_PULIDOR', 'P4_4_QUIMICO', 'P4_4_RADIOLOGO', 'P4_4_REALIZA', 'P4_4_RECEPCIONISTA', 'P4_4_RECOLECTOR', 'P4_4_REPARA', 'P4_4_REPARACION', 'P4_4_REPARADOR', 'P4_4_REPARTIDOR', 'P4_4_RESIDENTE', 'P4_4_SEGURIDAD', 'P4_4_SERVICIO', 'P4_4_SERVICIOS', 'P4_4_SERVIDOR', 'P4_4_SIEMBRA', 'P4_4_SISTEMAS', 'P4_4_SOLDADO', 'P4_4_SOLDADOR', 'P4_4_SUBGERENTE', 'P4_4_SUPERVISOR', 'P4_4_SURTIDOR', 'P4_4_TABLAJERO', 'P4_4_TABLAROQUERO', 'P4_4_TALACHERO', 'P4_4_TALLER', 'P4_4_TAPICERO', 'P4_4_TAQUERO', 'P4_4_TATUADOR', 'P4_4_TAXISTA', 'P4_4_TECNICO', 'P4_4_TIENE', 'P4_4_TORNERO', 'P4_4_TORTILLERO', 'P4_4_TRABAJA', 'P4_4_TRABAJADOR', 'P4_4_TRABAJO', 'P4_4_TRACTORISTA', 'P4_4_TRAILERO', 'P4_4_TRAMITADOR', 'P4_4_TRANSPORTISTA', 'P4_4_UBER', 'P4_4_VAQUERO', 'P4_4_VELADOR', 'P4_4_VENDE', 'P4_4_VENDEDOR', 'P4_4_VENTA', 'P4_4_VENTAS', 'P4_4_VETERINARIO', 'P4_4_VIDRIERO', 'P4_4_VIGILANTE', 'P4_4_YESERO', 'P4_4_ZAPATERO', 'P4_5_1_AB_1.0', 'P4_5_1_AB_2.0', 'P4_5_1_AB_3.0', 'P4_5_1_AB_8.0', 'P4_5_1_AB_9.0', 'P4_5_1_AB_b', 'P4_6_AB_1.0', 'P4_6_AB_2.0', 'P4_6_AB_3.0', 'P4_6_AB_9.0', 'P4_6_AB_b', 'P4_10_2_1_1.0', 'P4_10_2_1_2.0', 'P4_10_2_1_3.0', 'P4_10_2_1_4.0', 'P4_10_2_1_5.0', 'P4_10_2_1_b', 'P4_10_2_2_2.0', 'P4_10_2_2_3.0', 'P4_10_2_2_4.0', 'P4_10_2_2_5.0', 'P4_10_2_2_b', 'P4_10_2_3_4.0', 'P4_10_2_3_5.0', 'P4_10_2_3_b', 'P4_10_3_1_1.0', 'P4_10_3_1_2.0', 'P4_10_3_1_3.0', 'P4_10_3_1_4.0', 'P4_10_3_1_5.0', 'P4_10_3_1_b', 'P4_10_3_2_3.0', 'P4_10_3_2_4.0', 'P4_10_3_2_5.0', 'P4_10_3_2_b', 'P4_10_3_3_b', 'P4_13_1_1.0', 'P4_13_1_2.0', 'P4_13_1_3.0', 'P4_13_1_4.0', 'P4_13_1_5.0', 'P4_13_1_6.0', 'P4_13_1_7.0', 'P4_13_1_8.0', 'P4_13_1_98.0', 'P4_13_1_b', 'P4_13_2_1.0', 'P4_13_2_2.0', 'P4_13_2_3.0', 'P4_13_2_4.0', 'P4_13_2_5.0', 'P4_13_2_6.0', 'P4_13_2_7.0', 'P4_13_2_8.0', 'P4_13_2_98.0', 'P4_13_2_b', 'P4_13_3_1.0', 'P4_13_3_2.0', 'P4_13_3_3.0', 'P4_13_3_4.0', 'P4_13_3_5.0', 'P4_13_3_6.0', 'P4_13_3_7.0', 'P4_13_3_8.0', 'P4_13_3_98.0', 'P4_13_3_b', 'P4_13_4_1.0', 'P4_13_4_2.0', 'P4_13_4_3.0', 'P4_13_4_4.0', 'P4_13_4_5.0', 'P4_13_4_6.0', 'P4_13_4_7.0', 'P4_13_4_8.0', 'P4_13_4_98.0', 'P4_13_4_b', 'P4_13_5_1.0', 'P4_13_5_2.0', 'P4_13_5_3.0', 'P4_13_5_4.0', 'P4_13_5_5.0', 'P4_13_5_6.0', 'P4_13_5_7.0', 'P4_13_5_8.0', 'P4_13_5_98.0', 'P4_13_5_b', 'P4_13_6_1.0', 'P4_13_6_2.0', 'P4_13_6_3.0', 'P4_13_6_4.0', 'P4_13_6_5.0', 'P4_13_6_6.0', 'P4_13_6_7.0', 'P4_13_6_8.0', 'P4_13_6_98.0', 'P4_13_6_b', 'P4_13_7_1.0', 'P4_13_7_2.0', 'P4_13_7_3.0', 'P4_13_7_4.0', 'P4_13_7_5.0', 'P4_13_7_6.0', 'P4_13_7_7.0', 'P4_13_7_8.0', 'P4_13_7_98.0', 'P4_13_7_b'], 'P10': ['P10_1_1', 'P10_1_2', 'P10_1_3', 'P10_1_4', 'P10_1_5', 'P10_1_6', 'P10_1_7', 'P10_1_8', 'P10_1_9', 'P10_2', 'P10_3', 'P10_4_1', 'P10_4_2', 'P10_4_3', 'P10_5_01', 'P10_5_02', 'P10_5_03', 'P10_5_04', 'P10_5_05', 'P10_5_06', 'P10_5_07', 'P10_5_08', 'P10_5_09', 'P10_5_10', 'P10_5_11', 'P10_6ANIO', 'P10_6MES']}\n",
            "Epoch 1/120\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 3.4745 - accuracy: 0.0776\n",
            "Epoch 2/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.2039 - accuracy: 0.0817\n",
            "Epoch 3/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.0844 - accuracy: 0.1112\n",
            "Epoch 4/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.9833 - accuracy: 0.1450\n",
            "Epoch 5/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.8921 - accuracy: 0.1774\n",
            "Epoch 6/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.6544 - accuracy: 0.2454\n",
            "Epoch 7/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.5178 - accuracy: 0.2869\n",
            "Epoch 8/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.3903 - accuracy: 0.3440\n",
            "Epoch 9/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.2398 - accuracy: 0.3786\n",
            "Epoch 10/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.0501 - accuracy: 0.4397\n",
            "Epoch 11/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.9311 - accuracy: 0.4751\n",
            "Epoch 12/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7362 - accuracy: 0.5328\n",
            "Epoch 13/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.6204 - accuracy: 0.5718\n",
            "Epoch 14/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.5071 - accuracy: 0.6168\n",
            "Epoch 15/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4213 - accuracy: 0.6307\n",
            "Epoch 16/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3240 - accuracy: 0.6628\n",
            "Epoch 17/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2031 - accuracy: 0.6963\n",
            "Epoch 18/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0790 - accuracy: 0.7318\n",
            "Epoch 19/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0497 - accuracy: 0.7371\n",
            "Epoch 20/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0492 - accuracy: 0.7438\n",
            "Epoch 21/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9647 - accuracy: 0.7673\n",
            "Epoch 22/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9846 - accuracy: 0.7669\n",
            "Epoch 23/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8381 - accuracy: 0.7935\n",
            "Epoch 24/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7034 - accuracy: 0.8311\n",
            "Epoch 25/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.8534\n",
            "Epoch 26/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6279 - accuracy: 0.8598\n",
            "Epoch 27/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7191 - accuracy: 0.8378\n",
            "Epoch 28/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6574 - accuracy: 0.8514\n",
            "Epoch 29/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8266 - accuracy: 0.8250\n",
            "Epoch 30/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8855 - accuracy: 0.8265\n",
            "Epoch 31/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8236 - accuracy: 0.8182\n",
            "Epoch 32/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5962 - accuracy: 0.8601\n",
            "Epoch 33/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.8859\n",
            "Epoch 34/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.9110\n",
            "Epoch 35/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.9052\n",
            "Epoch 36/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9724 - accuracy: 0.8155\n",
            "Epoch 37/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7514 - accuracy: 0.8503\n",
            "Epoch 38/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.8793\n",
            "Epoch 39/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.9077\n",
            "Epoch 40/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3072 - accuracy: 0.9322\n",
            "Epoch 41/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3019 - accuracy: 0.9375\n",
            "Epoch 42/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9435\n",
            "Epoch 43/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.9355\n",
            "Epoch 44/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3501 - accuracy: 0.9353\n",
            "Epoch 45/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4708 - accuracy: 0.9063\n",
            "Epoch 46/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5576 - accuracy: 0.8923\n",
            "Epoch 47/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7382 - accuracy: 0.8658\n",
            "Epoch 48/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7317 - accuracy: 0.8601\n",
            "Epoch 49/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5770 - accuracy: 0.8846\n",
            "Epoch 50/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.9226\n",
            "Epoch 51/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.9431\n",
            "Epoch 52/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.9402\n",
            "Epoch 53/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4077 - accuracy: 0.9197\n",
            "Epoch 54/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.9338\n",
            "Epoch 55/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2238 - accuracy: 0.9549\n",
            "Epoch 56/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9644\n",
            "Epoch 57/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9637\n",
            "Epoch 58/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.9429\n",
            "Epoch 59/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9232 - accuracy: 0.8548\n",
            "Epoch 60/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2954 - accuracy: 0.7739\n",
            "Epoch 61/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.8366\n",
            "Epoch 62/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5400 - accuracy: 0.8767\n",
            "Epoch 63/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.9278\n",
            "Epoch 64/120\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.2475 - accuracy: 0.9479\n",
            "Epoch 65/120\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 0.1869 - accuracy: 0.9605\n",
            "Epoch 66/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9723\n",
            "Epoch 67/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9781\n",
            "Epoch 68/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9727\n",
            "Epoch 69/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9547\n",
            "Epoch 70/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1702 - accuracy: 0.8278\n",
            "Epoch 71/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9511 - accuracy: 0.8271\n",
            "Epoch 72/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5812 - accuracy: 0.8840\n",
            "Epoch 73/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.9095\n",
            "Epoch 74/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.9169\n",
            "Epoch 75/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.9342\n",
            "Epoch 76/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.9424\n",
            "Epoch 77/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9569\n",
            "Epoch 78/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1823 - accuracy: 0.9658\n",
            "Epoch 79/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2080 - accuracy: 0.9596\n",
            "Epoch 80/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2221 - accuracy: 0.9567\n",
            "Epoch 81/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4011 - accuracy: 0.9303\n",
            "Epoch 82/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.9218\n",
            "Epoch 83/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.9139\n",
            "Epoch 84/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5781 - accuracy: 0.9024\n",
            "Epoch 85/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.9153\n",
            "Epoch 86/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.9315\n",
            "Epoch 87/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.9567\n",
            "Epoch 88/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9709\n",
            "Epoch 89/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1327 - accuracy: 0.9761\n",
            "Epoch 90/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9754\n",
            "Epoch 91/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2273 - accuracy: 0.9625\n",
            "Epoch 92/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6795 - accuracy: 0.9114\n",
            "Epoch 93/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3457 - accuracy: 0.7933\n",
            "Epoch 94/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8414 - accuracy: 0.8515\n",
            "Epoch 95/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.8759\n",
            "Epoch 96/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.9291\n",
            "Epoch 97/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9590\n",
            "Epoch 98/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9694\n",
            "Epoch 99/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1271 - accuracy: 0.9748\n",
            "Epoch 100/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9813\n",
            "Epoch 101/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9834\n",
            "Epoch 102/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9778\n",
            "Epoch 103/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9776\n",
            "Epoch 104/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9767\n",
            "Epoch 105/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2956 - accuracy: 0.9511\n",
            "Epoch 106/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0917 - accuracy: 0.8500\n",
            "Epoch 107/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1012 - accuracy: 0.8119\n",
            "Epoch 108/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7293 - accuracy: 0.8592\n",
            "Epoch 109/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4177 - accuracy: 0.9100\n",
            "Epoch 110/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9367\n",
            "Epoch 111/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9549\n",
            "Epoch 112/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1403 - accuracy: 0.9695\n",
            "Epoch 113/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9794\n",
            "Epoch 114/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9843\n",
            "Epoch 115/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9857\n",
            "Epoch 116/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.1115 - accuracy: 0.9806\n",
            "Epoch 117/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.3916 - accuracy: 0.9395\n",
            "Epoch 118/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7862 - accuracy: 0.8668\n",
            "Epoch 119/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9508 - accuracy: 0.8461\n",
            "Epoch 120/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7873 - accuracy: 0.8543\n",
            "151/151 [==============================] - 0s 1ms/step\n",
            "Best Threshold: 0.9901000261306763 with G-Mean: 0.5296\n",
            "FPR: 0.464, TPR: 0.5232\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 - 0s - loss: 1.2759 - accuracy: 0.7390 - 311ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Classification Report'])"
      ],
      "metadata": {
        "id": "eNHBuX3EkQMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dad9069-dacc-4970-91c9-2c55f71d7529"
      },
      "id": "eNHBuX3EkQMv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.08      0.54      0.14       347\n",
            "     Class 2       0.94      0.52      0.67      4484\n",
            "\n",
            "    accuracy                           0.52      4831\n",
            "   macro avg       0.51      0.53      0.41      4831\n",
            "weighted avg       0.87      0.52      0.63      4831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "LBUCTEj7kQPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df54773-7af7-44ad-8c7e-5a7db2f05d54"
      },
      "id": "LBUCTEj7kQPq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 186  161]\n",
            " [2138 2346]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Clustered_NN_Classifier(key, dict_X, dict_y, Clustered_NN_Results = {}):\n",
        "    # Create a copy of the X and y datasets to prevent modifications in the original dataset\n",
        "    X = dict_X.copy()\n",
        "    y = dict_y.copy()\n",
        "    # Create list of columns that contain a survey answer except for the marital status question\n",
        "    survey_answers = [x for x in X.columns if not re.search(\"P3_8\",x) if not re.search(\"P10_7\",x) if re.search(\"P\\d\",x)]\n",
        "    # Create a dataframe that only has the survey answers columns\n",
        "    survey_df = X[survey_answers]\n",
        "    # Elbow curve is not calculated since it requires around 4 hours to compute\n",
        "    # Elbow curve to find optimal K\n",
        "    #cost = []\n",
        "    #K = range(1,15)\n",
        "    #for num_clusters in list(K):\n",
        "    #    kmode = KModes(n_clusters=num_clusters, init = \"random\", n_init = 5, verbose=1)\n",
        "    #    kmode.fit_predict(survey_df)\n",
        "    #    cost.append(kmode.cost_)\n",
        "    #pyplot.plot(K, cost, 'bx-')\n",
        "    #pyplot.xlabel('No. of clusters')\n",
        "    #pyplot.ylabel('Cost')\n",
        "    #pyplot.title('Elbow Method For Optimal k')\n",
        "    #pyplot.show()\n",
        "    # Building the model with x clusters\n",
        "    kmode = KModes(n_clusters=6, init = \"random\")\n",
        "    clusters = kmode.fit_predict(survey_df)\n",
        "    # Drop the columns from the original cluster\n",
        "    X = X.drop(columns=survey_answers)\n",
        "    # Add the cluster labels to the dataset\n",
        "    X['Group'] = clusters\n",
        "    # Enconde the clusters \n",
        "    X = pd.get_dummies(X, columns=['Group'])\n",
        "    # Change the y labels from 1 and 2 to 0 and 1 respectively\n",
        "    y.loc[y[key] == 1,key] = 0\n",
        "    y.loc[y[key] == 2,key] = 1\n",
        "    # Calculate the count of 0s and 1s\n",
        "    pos, neg = np.bincount(y[key])\n",
        "    # Calculate the count of values in y\n",
        "    total = neg + pos\n",
        "    # Calculate the class weight\n",
        "    weight_for_0 = (10 / pos) * (total)\n",
        "    weight_for_1 = (1 / neg) * (total)\n",
        "    # Create the class weight dictionary\n",
        "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "    # Grab the y information from the target dataset\n",
        "    y = y.astype('int').values\n",
        "    # Create the train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.values, y, random_state=18, stratify=y)\n",
        "    # Create a scaler instance\n",
        "    scaler = StandardScaler()\n",
        "    # Train the standard scaler using the X_train data\n",
        "    X_scaler = scaler.fit(X_train)\n",
        "    # Scale the X training data\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    # Scale the X test data\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    # Define the number of input features and hidden nodes for each layer.\n",
        "    number_input_features = len(X_train[0])\n",
        "    hidden_nodes_layer1 = 140\n",
        "    hidden_nodes_layer2 = 100\n",
        "    hidden_nodes_layer3 = 40\n",
        "    # Create instance of the neural network\n",
        "    nn = tf.keras.models.Sequential()\n",
        "    # First hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"swish\"))\n",
        "    # Second hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
        "    # Third hidden layer\n",
        "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"swish\"))\n",
        "    # Output layer\n",
        "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the model\n",
        "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    # Train the model \n",
        "    fit_model = nn.fit(X_train_scaled,y_train,epochs=120,class_weight=class_weight)\n",
        "    # Predict the results for the target question\n",
        "    predictions = nn.predict(X_test_scaled).ravel()\n",
        "    # calculate roc curves\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
        "    # ----------------------------------------------------\n",
        "    # REFERENCE https://towardsdatascience.com/optimal-threshold-for-imbalanced-classification-5884e870c293\n",
        "    # ----------------------------------------------------\n",
        "    # Calculate the G-Mean\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(gmean)\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    gmeanOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "    print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n",
        "    print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "    # plot the roc curve for the model\n",
        "    pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "    pyplot.plot(fpr, tpr, marker='.', label='Neural Network')\n",
        "    pyplot.plot(fprOpt, tprOpt, marker='*', label='Optimal Value')\n",
        "    # axis labels\n",
        "    pyplot.xlabel('False Positive Rate')\n",
        "    pyplot.ylabel('True Positive Rate')\n",
        "    pyplot.legend()\n",
        "    # show the plot\n",
        "    pyplot.show()\n",
        "    # Convert predictions to 0 or 1 according to the optimal threshold\n",
        "    threshold = thresholdOpt\n",
        "    # Label predictions using the threshold\n",
        "    binary_predictions = (predictions >= threshold).astype(int)\n",
        "    # Calculating the confusion matrix.\n",
        "    cm = confusion_matrix(y_test, binary_predictions)\n",
        "    # Evaluate the model using the test data\n",
        "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "    # Store the results results\n",
        "    Clustered_NN_Results[key] = {}\n",
        "    Clustered_NN_Results[key]['Predictions'] = binary_predictions\n",
        "    Clustered_NN_Results[key][\"Confusion Matrix\"] = cm\n",
        "    Clustered_NN_Results[key][\"Accuracy Score\"] = model_accuracy\n",
        "    Clustered_NN_Results[key][\"Classification Report\"] = classification_report(y_test, binary_predictions, target_names=['Class 1', 'Class 2'])    \n",
        "    return Clustered_NN_Results"
      ],
      "metadata": {
        "id": "qrolwxRunBKa"
      },
      "id": "qrolwxRunBKa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Clustered_NN_Results = Clustered_NN_Classifier('P10_8_1',dataset_dictionary['P10_8_1']['X'],dataset_dictionary['P10_8_1']['y'])"
      ],
      "metadata": {
        "id": "eomJfUXnnBRj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4675030-d3c3-40f7-85d3-d4417fe0ee14"
      },
      "id": "eomJfUXnnBRj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "453/453 [==============================] - 2s 2ms/step - loss: 3.4888 - accuracy: 0.0842\n",
            "Epoch 2/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.2267 - accuracy: 0.0827\n",
            "Epoch 3/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.1746 - accuracy: 0.1086\n",
            "Epoch 4/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.1129 - accuracy: 0.1230\n",
            "Epoch 5/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.0808 - accuracy: 0.1268\n",
            "Epoch 6/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3.0059 - accuracy: 0.1502\n",
            "Epoch 7/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.9613 - accuracy: 0.1738\n",
            "Epoch 8/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.8836 - accuracy: 0.1974\n",
            "Epoch 9/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.8028 - accuracy: 0.2181\n",
            "Epoch 10/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.7367 - accuracy: 0.2399\n",
            "Epoch 11/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.6595 - accuracy: 0.2658\n",
            "Epoch 12/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.5746 - accuracy: 0.2905\n",
            "Epoch 13/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.5324 - accuracy: 0.3103\n",
            "Epoch 14/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.4234 - accuracy: 0.3310\n",
            "Epoch 15/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3295 - accuracy: 0.3625\n",
            "Epoch 16/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.3195 - accuracy: 0.3755\n",
            "Epoch 17/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.2819 - accuracy: 0.3798\n",
            "Epoch 18/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1714 - accuracy: 0.4068\n",
            "Epoch 19/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1079 - accuracy: 0.4407\n",
            "Epoch 20/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 2.1137 - accuracy: 0.4385\n",
            "Epoch 21/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 2.0049 - accuracy: 0.4692\n",
            "Epoch 22/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.9478 - accuracy: 0.4812\n",
            "Epoch 23/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.8521 - accuracy: 0.5114\n",
            "Epoch 24/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7846 - accuracy: 0.5343\n",
            "Epoch 25/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7515 - accuracy: 0.5423\n",
            "Epoch 26/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.7001 - accuracy: 0.5566\n",
            "Epoch 27/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.6653 - accuracy: 0.5777\n",
            "Epoch 28/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.6435 - accuracy: 0.5837\n",
            "Epoch 29/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.5974 - accuracy: 0.5931\n",
            "Epoch 30/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.5511 - accuracy: 0.6046\n",
            "Epoch 31/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.5290 - accuracy: 0.6165\n",
            "Epoch 32/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.4545 - accuracy: 0.6417\n",
            "Epoch 33/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4201 - accuracy: 0.6473\n",
            "Epoch 34/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4395 - accuracy: 0.6438\n",
            "Epoch 35/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.4069 - accuracy: 0.6579\n",
            "Epoch 36/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.3422 - accuracy: 0.6706\n",
            "Epoch 37/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.3339 - accuracy: 0.6783\n",
            "Epoch 38/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2914 - accuracy: 0.6875\n",
            "Epoch 39/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.2431 - accuracy: 0.7002\n",
            "Epoch 40/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.3609 - accuracy: 0.6829\n",
            "Epoch 41/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.2652 - accuracy: 0.6975\n",
            "Epoch 42/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1793 - accuracy: 0.7154\n",
            "Epoch 43/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1443 - accuracy: 0.7238\n",
            "Epoch 44/120\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 1.1749 - accuracy: 0.7228\n",
            "Epoch 45/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1531 - accuracy: 0.7271\n",
            "Epoch 46/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1557 - accuracy: 0.7305\n",
            "Epoch 47/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.1472 - accuracy: 0.7297\n",
            "Epoch 48/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0795 - accuracy: 0.7476\n",
            "Epoch 49/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.1076 - accuracy: 0.7464\n",
            "Epoch 50/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0746 - accuracy: 0.7525\n",
            "Epoch 51/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0479 - accuracy: 0.7592\n",
            "Epoch 52/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0815 - accuracy: 0.7514\n",
            "Epoch 53/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0114 - accuracy: 0.7683\n",
            "Epoch 54/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0205 - accuracy: 0.7686\n",
            "Epoch 55/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0145 - accuracy: 0.7683\n",
            "Epoch 56/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9919 - accuracy: 0.7774\n",
            "Epoch 57/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 1.0029 - accuracy: 0.7738\n",
            "Epoch 58/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9574 - accuracy: 0.7800\n",
            "Epoch 59/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9602 - accuracy: 0.7828\n",
            "Epoch 60/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0674 - accuracy: 0.7736\n",
            "Epoch 61/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1.0915 - accuracy: 0.7627\n",
            "Epoch 62/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9710 - accuracy: 0.7787\n",
            "Epoch 63/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.9153 - accuracy: 0.7927\n",
            "Epoch 64/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8569 - accuracy: 0.8059\n",
            "Epoch 65/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8410 - accuracy: 0.8098\n",
            "Epoch 66/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8490 - accuracy: 0.8119\n",
            "Epoch 67/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8535 - accuracy: 0.8091\n",
            "Epoch 68/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8442 - accuracy: 0.8121\n",
            "Epoch 69/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8633 - accuracy: 0.8098\n",
            "Epoch 70/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8994 - accuracy: 0.8040\n",
            "Epoch 71/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8237 - accuracy: 0.8191\n",
            "Epoch 72/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8119 - accuracy: 0.8203\n",
            "Epoch 73/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8664 - accuracy: 0.8123\n",
            "Epoch 74/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8737 - accuracy: 0.8150\n",
            "Epoch 75/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8778 - accuracy: 0.8134\n",
            "Epoch 76/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8243 - accuracy: 0.8206\n",
            "Epoch 77/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.8333 - accuracy: 0.8233\n",
            "Epoch 78/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.9749 - accuracy: 0.8097\n",
            "Epoch 79/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8582 - accuracy: 0.8144\n",
            "Epoch 80/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7814 - accuracy: 0.8254\n",
            "Epoch 81/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7308 - accuracy: 0.8378\n",
            "Epoch 82/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7306 - accuracy: 0.8434\n",
            "Epoch 83/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7450 - accuracy: 0.8402\n",
            "Epoch 84/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7227 - accuracy: 0.8451\n",
            "Epoch 85/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7636 - accuracy: 0.8384\n",
            "Epoch 86/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7996 - accuracy: 0.8331\n",
            "Epoch 87/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7787 - accuracy: 0.8352\n",
            "Epoch 88/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7322 - accuracy: 0.8440\n",
            "Epoch 89/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7339 - accuracy: 0.8439\n",
            "Epoch 90/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7614 - accuracy: 0.8413\n",
            "Epoch 91/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7680 - accuracy: 0.8403\n",
            "Epoch 92/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7433 - accuracy: 0.8436\n",
            "Epoch 93/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7536 - accuracy: 0.8413\n",
            "Epoch 94/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6673 - accuracy: 0.8577\n",
            "Epoch 95/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7133 - accuracy: 0.8538\n",
            "Epoch 96/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7201 - accuracy: 0.8523\n",
            "Epoch 97/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7200 - accuracy: 0.8514\n",
            "Epoch 98/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7440 - accuracy: 0.8462\n",
            "Epoch 99/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6802 - accuracy: 0.8574\n",
            "Epoch 100/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7375 - accuracy: 0.8525\n",
            "Epoch 101/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7882 - accuracy: 0.8413\n",
            "Epoch 102/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6537 - accuracy: 0.8588\n",
            "Epoch 103/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5990 - accuracy: 0.8707\n",
            "Epoch 104/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.8789\n",
            "Epoch 105/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.8633\n",
            "Epoch 106/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7197 - accuracy: 0.8510\n",
            "Epoch 107/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.8187 - accuracy: 0.8454\n",
            "Epoch 108/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.7186 - accuracy: 0.8526\n",
            "Epoch 109/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6130 - accuracy: 0.8700\n",
            "Epoch 110/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6549 - accuracy: 0.8636\n",
            "Epoch 111/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.8760\n",
            "Epoch 112/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5914 - accuracy: 0.8772\n",
            "Epoch 113/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.8736\n",
            "Epoch 114/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6844 - accuracy: 0.8573\n",
            "Epoch 115/120\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.8589\n",
            "Epoch 116/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7008 - accuracy: 0.8556\n",
            "Epoch 117/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.7860 - accuracy: 0.8543\n",
            "Epoch 118/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.6544 - accuracy: 0.8608\n",
            "Epoch 119/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5798 - accuracy: 0.8782\n",
            "Epoch 120/120\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.5636 - accuracy: 0.8834\n",
            "151/151 [==============================] - 0s 1ms/step\n",
            "Best Threshold: 0.9965999722480774 with G-Mean: 0.5636\n",
            "FPR: 0.438, TPR: 0.5653\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 - 0s - loss: 1.2472 - accuracy: 0.7810 - 338ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Classification Report'])"
      ],
      "metadata": {
        "id": "3CjNqsWznBVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e23e46f-791f-4d40-b04e-c37e4be47dc3"
      },
      "id": "3CjNqsWznBVq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.09      0.56      0.16       347\n",
            "     Class 2       0.94      0.57      0.71      4484\n",
            "\n",
            "    accuracy                           0.57      4831\n",
            "   macro avg       0.52      0.56      0.43      4831\n",
            "weighted avg       0.88      0.57      0.67      4831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Clustered_NN_Results['P10_8_1']['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "OnIYPQaUnBZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9245699c-b3e1-44a0-e995-c16c5cdfafb9"
      },
      "id": "OnIYPQaUnBZk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 195  152]\n",
            " [1949 2535]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KMhm--G5Rp-"
      },
      "id": "6KMhm--G5Rp-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PythonData",
      "language": "python",
      "name": "pythondata"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}